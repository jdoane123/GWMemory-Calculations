{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-90b7a2d42b9c>, line 201)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-90b7a2d42b9c>\"\u001b[0;36m, line \u001b[0;32m201\u001b[0m\n\u001b[0;31m    Likelihood_dict[key] = Like\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mass = [60, 60, 60]\n",
    "dist2 = [5, 50, 100]\n",
    "\n",
    "def LambdaPeakGraph (mass, dist):\n",
    "    %pylab inline\n",
    "    %config Inline.Backend.figure_format = 'retina'\n",
    "\n",
    "    #from __future__ import division, print_function\n",
    "    import gwmemory\n",
    "    !pip install lalsuite \n",
    "\n",
    "    from pycbc import catalog\n",
    "    from pycbc.waveform import get_td_waveform, get_fd_waveform\n",
    "    from pycbc.waveform import td_approximants, fd_approximants\n",
    "    from pycbc.fft import fft\n",
    "\n",
    "    import numpy as np\n",
    "    import scipy as sp\n",
    "    import pylab\n",
    "    from scipy.fftpack import fft, rfft\n",
    "\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.mlab as mlab\n",
    "    from pycbc.filter import resample_to_delta_t, highpass\n",
    "    from pycbc.catalog import Merger\n",
    "    from pycbc.psd import interpolate, inverse_spectrum_truncation\n",
    "    from pycbc.waveform import get_td_waveform\n",
    "    from pycbc.filter.matchedfilter import match\n",
    "\n",
    "    from scipy import signal\n",
    "    from scipy.signal import butter, filtfilt, iirdesign, zpk2tf, freqz\n",
    "    import h5py\n",
    "    import json\n",
    "    import matplotlib.lines as mlines\n",
    "\n",
    "    def InnerProduct(a, b, Sn, df):\n",
    "\n",
    "        b_conj = np.conjugate(b)\n",
    "\n",
    "        integrand = []\n",
    "\n",
    "        for i in range(0,len(a)):\n",
    "            intgrnd = a[i]*b_conj[i]/Sn[i]\n",
    "            integrand.append(intgrnd)\n",
    "\n",
    "        result_complex = 4*np.sum(integrand)*df\n",
    "\n",
    "        result = np.real(result_complex)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def LogLikelihood(data, h_theta, Sn, df):\n",
    "\n",
    "        h_minus_d = h_theta - data\n",
    "\n",
    "        term = (-1.0/2)*InnerProduct(h_minus_d, h_minus_d, Sn, df)\n",
    "\n",
    "        result = (term)\n",
    "\n",
    "        return result\n",
    "    \n",
    "  \n",
    "      #In order to generate the memory we necessarily generate the time-domain oscillatory waveform\n",
    "    q = 1.\n",
    "    S1 = [0., 0., 0.]\n",
    "    S2 = [0., 0., 0.]\n",
    "\n",
    "    times = np.linspace(-0.08, 0.02, 10001)\n",
    "    #times = np.linspace(-0.98, .01, 10000)\n",
    "    surr = gwmemory.waveforms.Surrogate(q=q, S1=S1, S2=S2, MTot = mass, distance = dist, times=times)\n",
    "\n",
    "\n",
    "\n",
    "    inc = np.pi / 2\n",
    "    pol = 0\n",
    "\n",
    "    oscillatory, times = surr.time_domain_oscillatory(inc=inc, pol=pol)\n",
    "    memory, times = surr.time_domain_memory(inc=inc, pol=pol)\n",
    "\n",
    "    fig = figure(figsize=(12, 6))\n",
    "    fig.add_subplot(2, 1, 1)\n",
    "    plot(times, oscillatory['plus'], linestyle='--', color='b', alpha=0.5)\n",
    "    plot(times, oscillatory['cross'], linestyle='--', color='r', alpha=0.5)\n",
    "    plot(times, memory['plus'], linestyle='-.', color='b', alpha=0.5)\n",
    "    plot(times, memory['cross'], linestyle='-.', color='r', alpha=0.5)\n",
    "    plot(times, oscillatory['plus'] + memory['plus'], color='b')\n",
    "    plot(times, oscillatory['cross'] + memory['cross'], color='r')\n",
    "    axhline(0, linestyle=':', color='k')\n",
    "    xlim(-0.08, 0.02)\n",
    "\n",
    "    print (type (oscillatory))\n",
    "\n",
    "    print (dir(surr.time_domain_oscillatory))\n",
    "\n",
    "    print (len(times))\n",
    "\n",
    "    print (times.size)\n",
    "\n",
    "\n",
    "   # tight_layout()\n",
    "    #show()\n",
    "    #close()\n",
    "    \n",
    "    \n",
    "    mem_plus = memory['plus']\n",
    "    dt = times[1] - times[0]\n",
    "    window = signal.tukey(len(mem_plus))\n",
    "    win_mem= window*mem_plus\n",
    "    print (len(win_mem))\n",
    "    print(len(times))\n",
    "    freq_mem = np.fft.rfft(win_mem)*dt\n",
    "\n",
    "    dt = times[1] - times[0]\n",
    "    #print (help(np.fft.fftfreq))\n",
    "    fft_mem = np.fft.rfftfreq (len(win_mem),dt)                            \n",
    "    print (win_mem[0:10])\n",
    "    print (win_mem[50:60])\n",
    "    print (len(freq_mem))\n",
    "    print (len(fft_mem))\n",
    "\n",
    "\n",
    "\n",
    "    osci_plus = oscillatory['plus']\n",
    "    window = signal.tukey(len(osci_plus))\n",
    "    win_osc= window*osci_plus\n",
    "    freq_osc = np.fft.rfft(win_osc)*dt\n",
    "\n",
    "    fft_osc = np.fft.rfftfreq(len(win_osc), dt)                            \n",
    "    print (win_osc[0:10])\n",
    "    print (win_osc[50:60])\n",
    "    print (len(fft_osc))\n",
    "    print (len(freq_osc))\n",
    "    \n",
    "    \n",
    "    s = freq_osc + freq_mem\n",
    "\n",
    "        #Making psd \n",
    "    merger = Merger(\"GW150914\")\n",
    "    \n",
    "   \n",
    "    # Get the data from the Hanford detector\n",
    "    strain = merger.strain('H1')\n",
    "    df = strain.delta_f\n",
    "    psd = strain.psd(4)\n",
    "    asd = np.sqrt(psd)\n",
    "    asd_freqs = psd.sample_frequencies\n",
    "\n",
    "        ##Interpolating to make  memory and oscillatory component (in freq domain) and PSD equal. This will line them up\n",
    "    from scipy.interpolate import interp1d\n",
    "    sampfreq = 4096\n",
    "    datafreq = np.fft.fftfreq(freq_osc.size)*sampfreq\n",
    "    interpolate_psd = np.interp(datafreq, asd_freqs, psd)\n",
    "\n",
    "    #Template, adding in the lambda component. Will store log likelihood of the template\n",
    "    lambda_arr = np.arange(-10,10,.1)\n",
    "    like_arr = []\n",
    "    for weight in lambda_arr:\n",
    "        h_trial = freq_osc + weight*freq_mem\n",
    "        like_trial = LogLikelihood(s, h_trial, interpolate_psd, df)\n",
    "        like_arr.append(like_trial)\n",
    "        \n",
    "    import numpy as np\n",
    "    from numpy import asarray\n",
    "    #Normalizing the Likelihood array\n",
    "    likelihood1 = np.exp(asarray(like_arr))\n",
    "    Normal = likelihood1.sum()*.1\n",
    "    Norm = likelihood1/Normal\n",
    "    print (Normal)\n",
    "    print (Norm)\n",
    "\n",
    "\n",
    "    #Plotting the normalized likelihood array\n",
    "    x = lambda_arr \n",
    "    y = Norm\n",
    "    #pylab.semilogy(x,y) \n",
    "    pylab.plot(x,y)\n",
    "    pylab.xlim(-10, 10, 0.01)\n",
    "    pylab.xlabel('Lambda')\n",
    "    pylab.ylim(-.0003, .000, 0.001)\n",
    "    pylab.ylabel('Likelihood')\n",
    "    #plt.title(\"Likelihood for 60 solar massess and 5 megaparsecs\", y=1.08)\n",
    "\n",
    "    pylab.show() \n",
    "    \n",
    "    \n",
    "#for i in range(3):\n",
    "    #LambdaPeakGraph(mass[i], dist[i])\n",
    "\n",
    "    \n",
    "Likelihood_dict = {}\n",
    "area_dict = {}\n",
    "for w in np.arange(0,10):\n",
    "    area = square(w)\n",
    "    area_dict[w] = area\n",
    "\n",
    "for i in np.arange(3):\n",
    "    Likelihood = LambdaPeakGraph(mass[i], dist2[i])\n",
    "    key = ((mass[i]), (dist2[i])\n",
    "    Likelihood_dict[key] = Like\n",
    "\n",
    "for key, value in Likelihood_dict.items():\n",
    "    #key = mass[0][1]\n",
    "    #value = dist2[0][1]\n",
    "    plt.scatter(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr2 = [ 0.0463468   0.04643539  0.04652334  0.04661063  0.04669728  0.04678327\n",
    "  0.04686861  0.04695328  0.04703728  0.04712062  0.04720327  0.04728525\n",
    "  0.04736654  0.04744715  0.04752706  0.04760628  0.0476848   0.04776262\n",
    "  0.04783972  0.04791612  0.0479918   0.04806677  0.04814101  0.04821452\n",
    "  0.04828731  0.04835936  0.04843067  0.04850125  0.04857108  0.04864016\n",
    "  0.04870849  0.04877606  0.04884288  0.04890894  0.04897423  0.04903876\n",
    "  0.04910251  0.04916549  0.04922769  0.04928911  0.04934974  0.04940959\n",
    "  0.04946865  0.04952691  0.04958438  0.04964105  0.04969692  0.04975198\n",
    "  0.04980624  0.04985969  0.04991232  0.04996414  0.05001513  0.05006531\n",
    "  0.05011466  0.05016319  0.05021089  0.05025776  0.05030379  0.05034899\n",
    "  0.05039335  0.05043687  0.05047955  0.05052138  0.05056237  0.0506025\n",
    "  0.05064179  0.05068022  0.05071779  0.05075451  0.05079037  0.05082537\n",
    "  0.0508595   0.05089278  0.05092518  0.05095672  0.05098738  0.05101718\n",
    "  0.0510461   0.05107415  0.05110132  0.05112762  0.05115304  0.05117757\n",
    "  0.05120123  0.051224    0.0512459   0.0512669   0.05128702  0.05130625\n",
    "  0.0513246   0.05134206  0.05135862  0.0513743   0.05138908  0.05140298\n",
    "  0.05141597  0.05142808  0.05143929  0.05144961  0.05145903  0.05146756\n",
    "  0.05147519  0.05148192  0.05148776  0.05149269  0.05149674  0.05149988\n",
    "  0.05150212  0.05150347  0.05150392  0.05150347  0.05150212  0.05149988\n",
    "  0.05149674  0.05149269  0.05148776  0.05148192  0.05147519  0.05146756\n",
    "  0.05145903  0.05144961  0.05143929  0.05142808  0.05141597  0.05140298\n",
    "  0.05138908  0.0513743   0.05135862  0.05134206  0.0513246   0.05130625\n",
    "  0.05128702  0.0512669   0.0512459   0.051224    0.05120123  0.05117757\n",
    "  0.05115304  0.05112762  0.05110132  0.05107415  0.0510461   0.05101718\n",
    "  0.05098738  0.05095672  0.05092518  0.05089278  0.0508595   0.05082537\n",
    "  0.05079037  0.05075451  0.05071779  0.05068022  0.05064179  0.0506025\n",
    "  0.05056237  0.05052138  0.05047955  0.05043687  0.05039335  0.05034899\n",
    "  0.05030379  0.05025776  0.05021089  0.05016319  0.05011466  0.05006531\n",
    "  0.05001513  0.04996414  0.04991232  0.04985969  0.04980624  0.04975198\n",
    "  0.04969692  0.04964105  0.04958438  0.04952691  0.04946865  0.04940959\n",
    "  0.04934974  0.04928911  0.04922769  0.04916549  0.04910251  0.04903876\n",
    "  0.04897423  0.04890894  0.04884288  0.04877606  0.04870849  0.04864016\n",
    "  0.04857108  0.04850125  0.04843067  0.04835936  0.04828731  0.04821452\n",
    "  0.04814101  0.04806677]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr3 = [ 0.04906414  0.04908757  0.04911079  0.04913382  0.04915663  0.04917925\n",
    "  0.04920166  0.04922387  0.04924587  0.04926767  0.04928926  0.04931064\n",
    "  0.04933182  0.0493528   0.04937356  0.04939413  0.04941448  0.04943463\n",
    "  0.04945457  0.0494743   0.04949382  0.04951314  0.04953225  0.04955115\n",
    "  0.04956984  0.04958832  0.04960659  0.04962465  0.0496425   0.04966015\n",
    "  0.04967758  0.0496948   0.04971181  0.04972861  0.0497452   0.04976157\n",
    "  0.04977774  0.04979369  0.04980943  0.04982496  0.04984028  0.04985538\n",
    "  0.04987027  0.04988495  0.04989942  0.04991367  0.04992771  0.04994153\n",
    "  0.04995514  0.04996854  0.04998172  0.04999469  0.05000744  0.05001998\n",
    "  0.0500323   0.05004441  0.0500563   0.05006797  0.05007944  0.05009068\n",
    "  0.05010171  0.05011252  0.05012312  0.0501335   0.05014367  0.05015361\n",
    "  0.05016335  0.05017286  0.05018216  0.05019124  0.0502001   0.05020875\n",
    "  0.05021717  0.05022539  0.05023338  0.05024115  0.05024871  0.05025605\n",
    "  0.05026317  0.05027007  0.05027676  0.05028323  0.05028947  0.0502955\n",
    "  0.05030132  0.05030691  0.05031228  0.05031744  0.05032237  0.05032709\n",
    "  0.05033159  0.05033587  0.05033993  0.05034377  0.05034739  0.05035079\n",
    "  0.05035398  0.05035694  0.05035968  0.05036221  0.05036451  0.0503666\n",
    "  0.05036847  0.05037011  0.05037154  0.05037275  0.05037374  0.05037451\n",
    "  0.05037505  0.05037538  0.05037549  0.05037538  0.05037505  0.05037451\n",
    "  0.05037374  0.05037275  0.05037154  0.05037011  0.05036847  0.0503666\n",
    "  0.05036451  0.05036221  0.05035968  0.05035694  0.05035398  0.05035079\n",
    "  0.05034739  0.05034377  0.05033993  0.05033587  0.05033159  0.05032709\n",
    "  0.05032237  0.05031744  0.05031228  0.05030691  0.05030132  0.0502955\n",
    "  0.05028947  0.05028323  0.05027676  0.05027007  0.05026317  0.05025605\n",
    "  0.05024871  0.05024115  0.05023338  0.05022539  0.05021717  0.05020875\n",
    "  0.0502001   0.05019124  0.05018216  0.05017286  0.05016335  0.05015361\n",
    "  0.05014367  0.0501335   0.05012312  0.05011252  0.05010171  0.05009068\n",
    "  0.05007944  0.05006797  0.0500563   0.05004441  0.0500323   0.05001998\n",
    "  0.05000744  0.04999469  0.04998172  0.04996854  0.04995514  0.04994153\n",
    "  0.04992771  0.04991367  0.04989942  0.04988495  0.04987027  0.04985538\n",
    "  0.04984028  0.04982496  0.04980943  0.04979369  0.04977774  0.04976157\n",
    "  0.0497452   0.04972861  0.04971181  0.0496948   0.04967758  0.04966015\n",
    "  0.0496425   0.04962465  0.04960659  0.04958832  0.04956984  0.04955115\n",
    "  0.04953225  0.04951314]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambda_arr = np.arange(-10,10,.1)\n",
    "like_arr = []\n",
    "    for weight in lambda_arr:\n",
    "        h_trial = freq_osc + weight*freq_mem\n",
    "        like_trial = LogLikelihood(s, h_trial, interpolate_psd, df)\n",
    "        like_arr.append(like_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "likelihood1 = np.exp(asarray(like_arr))\n",
    "Normal = likelihood1.sum()*.1\n",
    "Norm = likelihood1/Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Confidence Interval (Estimate)\n",
    "sample_mean = mean(arr1)\n",
    "sample_90ci = 1.92 * sem(arr1)\n",
    "sample_min = sample_mean - sample_90ci\n",
    "sample_max = sample_mean + sample_90ci\n",
    "\n",
    "x = lambda_arr \n",
    "y = arr1\n",
    "#pylab.semilogy(x,y) \n",
    "pylab.plot(x,y)\n",
    "pylab.xlim(-10, 10, 0.01)\n",
    "pylab.xlabel('Lambda')\n",
    "pylab.ylim(-.0003, .000, 0.001)\n",
    "pylab.ylabel('Likelihood')\n",
    "pylab.title(\"Confidence interval for 60 Solar masses, 5MgPc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Confidence Interval (Estimate)\n",
    "sample_mean = mean(arr2)\n",
    "sample_90ci = 1.92 * sem(arr2)\n",
    "sample_min = sample_mean - sample_90ci\n",
    "sample_max = sample_mean + sample_90ci\n",
    "\n",
    "x = lambda_arr \n",
    "y = arr2\n",
    "#pylab.semilogy(x,y) \n",
    "pylab.plot(x,y)\n",
    "pylab.xlim(-10, 10, 0.01)\n",
    "pylab.xlabel('Lambda')\n",
    "pylab.ylim(-.0003, .000, 0.001)\n",
    "pylab.ylabel('Likelihood')\n",
    "pylab.title(\"Confidence interval for 60 Solar masses, 50MgPc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Confidence Interval (Estimate)\n",
    "sample_mean = mean(arr3)\n",
    "sample_90ci = 1.92 * sem(arr3)\n",
    "sample_min = sample_mean - sample_90ci\n",
    "sample_max = sample_mean + sample_90ci\n",
    "\n",
    "x = lambda_arr \n",
    "y = arr3\n",
    "#pylab.semilogy(x,y) \n",
    "pylab.plot(x,y)\n",
    "pylab.xlim(-10, 10, 0.01)\n",
    "pylab.xlabel('Lambda')\n",
    "pylab.ylim(-.0003, .000, 0.001)\n",
    "pylab.ylabel('Likelihood')\n",
    "pylab.title(\"Confidence interval for 60 Solar masses, 100MgPc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2nd attemp at Confidence intervl calculation (would be performed for arr1, 2, and 3 if correct.)\n",
    "import numpy as np, scipy.stats as st\n",
    "\n",
    "a = arr1\n",
    "st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stacking the data\n",
    "average_list = []\n",
    "\n",
    "for i in range (200)\n",
    "    (arr1+arr2+arr3)/3\n",
    "    averaged_list.append\n",
    "    \n",
    "x = lambda_arr \n",
    "y = average_list\n",
    "#pylab.semilogy(x,y) \n",
    "pylab.plot(x,y)\n",
    "pylab.xlim(-10, 10, 0.01)\n",
    "pylab.xlabel('Lambda')\n",
    "pylab.ylim(-.0003, .000, 0.001)\n",
    "pylab.ylabel('Stacked Likelihood')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
